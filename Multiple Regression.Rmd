---
title: "Regression Project"
author: "Thomas Townsley, John Carr, Matthew Lewis"
date: "December 7th, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(readr)
library(GGally)
library(car)
library(broom)

```
## Abstract
One parapgraph summary what we set out to learn and what final conclusions were.


```{r 1.1}
# 1. Abstract
```
## Introduction
Our goal is to build a model that can predict the price of a home in the Washington DC area. If we had pertinent data on that home, based on the same data to other homes in the area and their prices, but not the price, we will be able to predict what the price should be. Also, this model would be useful in determining what the price of a home in DC should cost even if there is a price already associated with it. For example, if one were to be in the market for such a home, this model would help the buyer or seller understand what would be a reasonable final price. This would inform the amount a buyer could/should offer, or the price a seller could justifiably list the home at. Data such as land area of the home, number of rooms, year built, etc. will power the predictive algorithym. As we began the discovery of this project, we anticipated that variables such as land area and number of rooms would be the most significant.

```{r 2.1}
# 2. Introduction

```
## Overview of the Dataset

single observation NOT YET excluded

Our dataset is titled D.C. Residential Properties and was acquired on kaggle.com. This dataset shows real property information, including most recent sales prices as of July 2018, for properties located in Washington, D.C. There are a number of variables that we beleive would be useful to us in achieving our goal, with "Condition" being the main conditional variable we use. We eliminated some variables that we decided would not be relevant or useful immediately. 

One way we manipulated the original dataset is by transforming the SALEDATE variable into separate variables for SALEYEAR, SALEMONTH and SALEDAY. We did this because we found little significance to SALEDATE as each was unique and spreadout, and thought there might be more significance in using individual parts of the dates at higher levels. We kept the original SALEDATE column in the dataset, as well.

Description of variables:
BATHRM (numeric): Number of full bathrooms
HF_BATHRM (numeric): Number of half bathrooms (no bathtub or shower)
ROOMS (numeric): Total number of rooms
BEDRM (numeric): Number of bedrooms
AYB (numeric): The earliest time the main portion of the building was built
YR_RMDL (numeric): Year structure was remodeled
STORIES (numeric): Number of stories in primary dwelling
SALEDATE (date): Date of most recent sale
SALEMONTH (numeric): Column we created for the calendar month of the most recent sale
SALEDAY (numeric): Column we created for the calendar day of the most recent sale
SALEYEAR (numeric): Column we created for the calendar year of the most recent sale
GBA (numeric): Gross building area in square feet
CNDTN (factor): Condition
LANDAREA (numeric): Land area of property in square feet
PRICE (numeric): Price of most recent sale

```{r 3.1}

# 3. Overview of the dataset

```
## Exploratory Analysis



```{r 4.1}

# 4. Exploratory analysis

houses <- read.csv("DC_properties_clean.csv")
summary(houses)

# Exclude Random Rows
excl_rows <- houses[sample(nrow(houses), 5), ]
houses <- setdiff(houses, excl_rows)

fit <- lm(data = houses, PRICE ~ BATHRM + HF_BATHRM  + ROOMS + BEDRM + AYB + YR_RMDL + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)

#####################################################

#Thomas's exploratory analysis and modeling

#First step: look at all possible correlations minus sale date because it wouldn't allow that many factors in the pairs function ¯\_(ツ)_/¯

int.vectors <- data.frame(houses$HF_BATHRM, houses$BATHRM, houses$ROOMS, houses$BEDRM,houses$AYB, houses$YR_RMDL, houses$PRICE, houses$SALEDAY, houses$SALEMONTH, houses$SALEYEAR, houses$STORIES, houses$LANDAREA, houses$GBA, houses$CNDTN)

View(int.vectors)

ggpairs(int.vectors)

#Observations
# Looks like the variables ROOMS, BATHRM, BEDRM, GBA, STORIES, LANDAREA, SALEYEAR, and PRICE have the highest correlation across the board i.e > |.35|. 

#Next making a pairs plot with just the above variables

int.vectors2 <- data.frame(houses$ROOMS, houses$BATHRM, houses$BEDRM, houses$GBA, houses$LANDAREA, houses$SALEYEAR, houses$PRICE)

ggpairs(int.vectors2)

#Now all variables look pretty like have predictive value regarding price. Notice that SALEYEAR is not correlated to anything but PRICE. Should we attempt to explain this, or throw the variable out? 

fit2 <- lm(data = houses, PRICE ~ ROOMS + BATHRM + BEDRM + GBA + LANDAREA + SALEYEAR)
anova(fit)
anova(fit2)

leveragePlots(fit2, pch = 16)

#Comaparing models

summary(fit)
summary(fit2)

#Given summary data from both models we can conclude ROOMS, BATHRM, BEDRM, GBA, LANDAREA, SALEYEAR, and CNDNTVeryGood are predictors of PRICE

#plotting and analyzing residuals 

fit2 <- augment(fit2)
ggplot(fit2, aes (x = .fitted, y = .resid))+
  geom_point() + 
  geom_hline(yintercept = 0, linetype = 2)+
  labs(x = "Fitted Values", y = "Residuals")

#other tests

qqplot(fit2, pch =16 )

shapiro.test(fit2)

ncvTest(fit2)


########################################################

# Matt's exploratory analysis and modeling

#Histograms for each variable

ggplot(houses, aes(x = BATHRM))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Bathrooms", title="Histogram of Bathrooms")

ggplot(houses, aes(x = HF_BATHRM))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Half Bathrooms", title="Histogram of Half Bathrooms")

ggplot(houses, aes(x = ROOMS))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Rooms", title="Histogram of Rooms")

ggplot(houses, aes(x = BEDRM))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Bed Rooms", title="Histogram of Bed Rooms")

ggplot(houses, aes(x = AYB))+
  geom_histogram(color="black", fill="light gray", binwidth = 10)+
  labs(x="Year Built", title="Histogram of Year Built")

ggplot(houses, aes(x = YR_RMDL))+
  geom_histogram(color="black", fill="light gray", binwidth = 10)+
  labs(x="Year Remodelled", title="Histogram of Year Remodelled")

ggplot(houses, aes(x = STORIES))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Stories", title="Histogram of Stories")

ggplot(houses, aes(x = SALEYEAR))+
  geom_histogram(color="black", fill="light gray", binwidth = 5)+
  labs(x="Year Sold", title="Histogram of Year Sold")

ggplot(houses, aes(x = SALEMONTH))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Month Sold", title="Histogram of Month Sold")

ggplot(houses, aes(x = SALEDAY))+
  geom_histogram(color="black", fill="light gray", binwidth = 4)+
  labs(x="Day Sold", title="Histogram of Day Sold")

ggplot(houses, aes(x = GBA))+
  geom_histogram(color="black", fill="light gray", binwidth = 100)+
  labs(x="Square Footage", title="Histogram of Square Footage")

ggplot(houses, aes(x = LANDAREA))+
  geom_histogram(color="black", fill="light gray", binwidth = 100)+
  labs(x="Land Area", title="Histogram of Land Area")

ggplot(houses, aes(x = CNDTN))+
  geom_bar(color="black", fill="light gray")+
  labs(x="Land Area", title="Bar Plot of Land Area")


# Re-order only categorical feature (factor)

houses$CNDTN <- factor(houses$CNDTN, levels = c("Fair", "Average", "Good", "Very Good", "Excellent"))

# Fit LM model with all features included

fit <- lm(data = houses, PRICE ~ BATHRM + HF_BATHRM  + ROOMS + BEDRM + AYB + YR_RMDL + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)

# Review ANOVA and compare F statistic

anova(fit)

# Review p-values, check sign of estimates

summary(fit)

# Residual plot and look for non-constant variance

fit.df <- augment(fit)
ggplot(fit.df, aes(x = .fitted, y = .resid))+
  geom_point()+
  geom_hline(yintercept = 0, linetype = 2)+
  labs( x = "Fitted Values", y = "Residuals")

# Shapiro-Wilk test for normality

shapiro.test(fit$residuals)

# ncvTest for constant variance

ncvTest(fit)

# Variance Inflation Factor (used to identify multicllinearity >= 10)

vif(fit)

# Review R2 value
# From summary above: adjusted R^2 = .6984

# Drop non-significant predictor variables (Droped AYB: +.0002, Rooms: No change, other lower)
fit <- lm(data = houses, PRICE ~ BATHRM + HF_BATHRM  + BEDRM + YR_RMDL + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)
summary(fit)

# If multicollinearity is present, drop one correlated variable (None present)

# Transform the outcome variable if the residual plot looks suspicious
powerTransform(houses$PRICE) #.33 -> sqrt
# log lowers R2: .6585
fit <- lm(data = houses, log(PRICE) ~ BATHRM + HF_BATHRM  + BEDRM + YR_RMDL + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)
summary(fit)
# sqrt increase R2: .7471, drop YR_RMDL + .0001
fit <- lm(data = houses, sqrt(PRICE) ~ BATHRM + HF_BATHRM  + BEDRM  + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)
summary(fit)
# inverse drastically decrease
fit <- lm(data = houses, I(1/PRICE) ~ BATHRM + HF_BATHRM  + BEDRM  + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)
summary(fit)

#Variable Transformations
powerTransform(houses$BATHRM) # didn't work
powerTransform(houses$HF_BATHRM) # didn't work
powerTransform(houses$BEDRM) # didn't work
powerTransform(houses$STORIES) # didn't work
powerTransform(houses$SALEMONTH) # -1.04 -> INVERSE
powerTransform(houses$SALEDATE) # didn't work
powerTransform(houses$SALEYEAR) # didn't work
powerTransform(houses$GBA) # -.08 -> LOG
powerTransform(houses$CNDTN) # didn't work
powerTransform(houses$LANDAREA) # .35 -> SQRT
fit <- lm(data = houses, sqrt(PRICE) ~ BATHRM + HF_BATHRM  + BEDRM + STORIES + SALEMONTH + I(1/SALEMONTH) + SALEDAY + SALEYEAR +GBA + log(GBA) + CNDTN + LANDAREA + sqrt(LANDAREA))
summary(fit) # R^2 increased to .7479

#Interactions
#fit <- lm(data = houses, sqrt(PRICE) ~ .*.) 
#summary(fit)

shapiro.test(fit$residuals)
ncvTest(fit)
vif(fit)

# Test on excluded rows
predict(fit, newdata = excl_rows, interval = "predict")

######################################

# John's exploratory analysis

# scatterplots
# price by room
room_price <- ggplot(houses, aes(x = ROOMS, y = PRICE))
room_price + geom_point()

# price by year
year_price <- ggplot(houses, aes(x = SALEYEAR, y = PRICE))
year_price + geom_point()

# price by month
month_price <- ggplot(houses, aes(x = SALEMONTH, y = PRICE))
month_price + geom_point()

# price by day of month
day_price <- ggplot(houses, aes(x = SALEDAY, y = PRICE))
day_price + geom_point()

# Boxplots to identify outliers
boxplot(houses$BATHRM, main="Bathrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$BATHRM)$out))

boxplot(houses$HF_BATHRM, main="Half Bathrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$HF_BATHRM)$out))

boxplot(houses$ROOMS, main="Rooms", sub=paste("Outlier rows: ", boxplot.stats(houses$ROOMS)$out))

boxplot(houses$BEDRM, main="Bedrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$BEDRM)$out))

boxplot(houses$AYB, main="Year Built", sub=paste("Outlier rows: ", boxplot.stats(houses$AYB)$out))

boxplot(houses$YR_RMDL, main="Year Remodeled", sub=paste("Outlier rows: ", boxplot.stats(houses$YR_RMDL)$out))

boxplot(houses$STORIES, main="Stories", sub=paste("Outlier rows: ", boxplot.stats(houses$STORIES)$out))

boxplot(houses$SALEYEAR, main="Year of Most Recent Sale", sub=paste("Outlier rows: ", boxplot.stats(houses$SALEYEAR)$out))

boxplot(houses$GBA, main="Gross Building Area", sub=paste("Outlier rows: ", boxplot.stats(houses$GBA)$out))

boxplot(houses$CNDTN, main="Condition", sub=paste("Outlier rows: ", boxplot.stats(houses$CNDTN)$out))

boxplot(houses$LANDAREA, main="Land Area", sub=paste("Outlier rows: ", boxplot.stats(houses$LANDAREA)$out))

boxplot(houses$PRICE, main="Price", sub=paste("Outlier rows: ", boxplot.stats(houses$PRICE)$out))

# Use corrplot to display a correlation matrix of that variables
library(corrplot)
corr_matrix <- cor(data.frame(houses$HF_BATHRM, houses$BATHRM, houses$ROOMS, houses$BEDRM,houses$AYB, houses$YR_RMDL, houses$PRICE, houses$SALEDAY, houses$SALEMONTH, houses$SALEYEAR, houses$STORIES, houses$LANDAREA, houses$GBA))
corrplot(corr_matrix, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

# fit initial model
fit_jc <- lm(data = houses, PRICE ~ BATHRM + HF_BATHRM  + ROOMS + BEDRM + AYB + YR_RMDL + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)

# check summary of initial model
# here we see the variables that are not significant in this model: ROOMS, AYB, YR_RMDL, STORIES, SALEMONTH
summary(fit_jc)

#second model
fit2_jc <- lm(data = houses, PRICE ~ BATHRM + HF_BATHRM  + BEDRM + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)

summary(fit2_jc)

# capture model summary as an object
modelSummary <- summary(fit2_jc)

# model coefficients
modelCoeffs <- modelSummary$coefficients

```
## Identification and Evaluation of Suitable Model

```{r 5.1}

# 5. Identification and evaluation of suitable model

#using AIC & BIC for model comparison
AIC(fit_jc) # AIC ==> 56607.77
BIC(fit_jc) # BIC ==> 56708.59

AIC(fit2_jc) # AIC ==> 56606.06
BIC(fit2_jc) # BIC ==> 56678.87

# The AIC and BIC for fit2_jc are both lower, so that is the better model

```
## Application of the Model

```{r 6.1}

# 6. Application of the model 

```
## Limitations and Assumptions

```{r 7.1}

# 7. Limitations and assumptions 

```




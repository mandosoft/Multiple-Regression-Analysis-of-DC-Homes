---
title: "Multiple Regression Analysis of D.C. Homes"
author: "Thomas Townsley, John Carr, Matthew Lewis"
date: "December 7th, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(readr)
library(car)
library(broom)
library(corrplot)
library(gridExtra)
```
## Abstract
Our goal with this project was to build a model that would predict the price of a home in the Washington D.C. area. We used a dataset that included 2,000 observations of other homes in the area with pertinent data to power the model. Our final model had an R<sup>2</sup> of 0.75, which we believe to be strong. When we run the predictor three out of the five lines we removed from the dataset are predicted acurately. Our conclusion is that our model would allow us to achieve the business need we set out to solve.

## Introduction

With our model, if we had pertinent data on a home in D.C., but not the price, we will be able to predict what the price should be. Also, this model would be useful in determining what the price of a home in DC should cost even if there is a price already associated with it. For example, if one were to be in the market for such a home, this model would help the buyer or seller understand what would be a reasonable final price. This would inform the amount a buyer could/should offer, or the price a seller could justifiably list the home at. Data such as land area of the home, number of rooms, year built, etc. will power the predictive algorithm. As we began the discovery of this project, we anticipated that variables such as land area and number of rooms would be the most significant.

## Overview of the dataset

Our dataset is titled D.C. Residential Properties and was acquired on kaggle.com. This dataset shows real property information, including most recent sales prices as of July 2018, for properties located in Washington, D.C. There are a number of variables that we beleive would be useful to us in achieving our goal, with "Condition" being the main categorical variable we use. We eliminated some variables that we decided would not be relevant or useful immediately. 

One way we manipulated the original dataset is by transforming the SALEDATE variable into separate variables for SALEYEAR, SALEMONTH and SALEDAY. We did this because we found little significance to SALEDATE as each date was unique, spreadout, and made it difficult to analyze model accuracy with thousands of p-scores. We hypothesized that there might be more significance in using individual parts of the dates at higher levels. Hoewver, We did keep the original SALEDATE column in the dataset, but did not use it for analysis.

Description of variables:
BATHRM (numeric): Number of full bathrooms
HF_BATHRM (numeric): Number of half bathrooms (no bathtub or shower)
ROOMS (numeric): Total number of rooms
BEDRM (numeric): Number of bedrooms
AYB (numeric): The earliest time the main portion of the building was built
YR_RMDL (numeric): Year structure was remodeled
STORIES (numeric): Number of stories in primary dwelling
SALEDATE (date): Date of most recent sale
SALEMONTH (numeric): Column we created for the calendar month of the most recent sale
SALEDAY (numeric): Column we created for the calendar day of the most recent sale
SALEYEAR (numeric): Column we created for the calendar year of the most recent sale
GBA (numeric): Gross building area in square feet
CNDTN (factor): Condition
LANDAREA (numeric): Land area of property in square feet
PRICE (numeric): Price of most recent sale

```{r 3.1, echo=FALSE}

houses <- read.csv("DC_properties_clean.csv")

excl_rows <- houses[sample(nrow(houses), 5), ] # Exclude Random Rows
houses <- setdiff(houses, excl_rows)

houses$CNDTN <- factor(houses$CNDTN, order = TRUE, levels = c("Fair", "Average", "Good", "Very Good", "Excellent"))

```

## Exploration of Dataset

```{r 4.1, echo=FALSE}


require(gridExtra)

plot1 <- ggplot(houses, aes(x = BATHRM))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Bathrooms", title="Bathrooms")

plot2 <- ggplot(houses, aes(x = HF_BATHRM))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Half Bathrooms", title="Half Bathrooms")

plot3 <- ggplot(houses, aes(x = ROOMS))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Rooms", title="Rooms")

plot4 <- ggplot(houses, aes(x = BEDRM))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Bed Rooms", title="Bed Rooms")

grid.arrange(plot1, plot2, plot3, plot4, nrow =2, ncol = 2)



plot5 <- ggplot(houses, aes(x = AYB))+
  geom_histogram(color="black", fill="light gray", binwidth = 10)+
  labs(x="Year Built", title="Year Built")

plot6 <- ggplot(houses, aes(x = YR_RMDL))+
  geom_histogram(color="black", fill="light gray", binwidth = 10)+
  labs(x="Year Remodeled", title="Year Remodeled")

plot7 <- ggplot(houses, aes(x = STORIES))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Stories", title="Stories")

plot8 <- ggplot(houses, aes(x = SALEYEAR))+
  geom_histogram(color="black", fill="light gray", binwidth = 5)+
  labs(x="Year Sold", title="Year Sold")

grid.arrange(plot5, plot6, plot7, plot8, nrow =2, ncol = 2)



plot9 <- ggplot(houses, aes(x = SALEMONTH))+
  geom_histogram(color="black", fill="light gray", binwidth = 1)+
  labs(x="Month Sold", title="Month Sold")

plot10 <- ggplot(houses, aes(x = SALEDAY))+
  geom_histogram(color="black", fill="light gray", binwidth = 4)+
  labs(x="Day Sold", title="Day Sold")

plot11 <- ggplot(houses, aes(x = GBA))+
  geom_histogram(color="black", fill="light gray", binwidth = 100)+
  labs(x="Square Footage", title="Square Footage")

plot12 <- ggplot(houses, aes(x = LANDAREA))+
  geom_histogram(color="black", fill="light gray", binwidth = 100)+
  labs(x="Land Area", title="Land Area")

grid.arrange(plot9, plot10, plot11, plot12, nrow =2, ncol = 2)


ggplot(houses, aes(x = CNDTN))+
  geom_bar(color="black", fill="light gray")+
  labs(x="Condition of Home", title="Home Condition")



# Boxplots to identify outliers

par(mfrow = c(1,2))
boxplot(houses$BATHRM, main="Bathrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$BATHRM)$out))

boxplot(houses$HF_BATHRM, main="Half Bathrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$HF_BATHRM)$out))

par(mfrow = c(1,2))
boxplot(houses$ROOMS, main="Rooms", sub=paste("Outlier rows: ", boxplot.stats(houses$ROOMS)$out))

boxplot(houses$BEDRM, main="Bedrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$BEDRM)$out))


par(mfrow = c(1,2))
boxplot(houses$AYB, main="Year Built", sub=paste("Outlier rows: ", boxplot.stats(houses$AYB)$out))

boxplot(houses$YR_RMDL, main="Year Remodeled", sub=paste("Outlier rows: ", boxplot.stats(houses$YR_RMDL)$out))

par(mfrow = c(1,2))
boxplot(houses$STORIES, main="Stories", sub=paste("Outlier rows: ", boxplot.stats(houses$STORIES)$out))

boxplot(houses$SALEYEAR, main="Year of Most Recent Sale", sub=paste("Outlier rows: ", boxplot.stats(houses$SALEYEAR)$out))

par(mfrow = c(1,2))
boxplot(houses$GBA, main="Gross Building Area", sub=paste("Outlier rows: ", boxplot.stats(houses$GBA)$out))

boxplot(houses$CNDTN, main="Condition", sub=paste("Outlier rows: ", boxplot.stats(houses$CNDTN)$out))

par(mfrow = c(1,2))
boxplot(houses$LANDAREA, main="Land Area", sub=paste("Outlier rows: ", boxplot.stats(houses$LANDAREA)$out))

boxplot(houses$PRICE, main="Price", sub=paste("Outlier rows: ", boxplot.stats(houses$PRICE)$out))

# Boxplots to identify outliers

boxa <- boxplot(houses$BATHRM, main="Bathrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$BATHRM)$out))

boxb <- boxplot(houses$HF_BATHRM, main="Half Bathrooms", sub=paste("Outlier rows: ", boxplot.stats(houses$HF_BATHRM)$out))

boxc <- boxplot(houses$ROOMS, main="Rooms", sub=paste("Outlier rows: ", boxplot.stats(houses$ROOMS)$out))



```

```{r}

```

###Scatter Plots of Price by Room, Day, Month, and Year of Sale

```{r, echo=FALSE}

# scatterplots


# price by room
room_price <- ggplot(houses, aes(x = ROOMS, y = PRICE))
room_price_plot <- room_price + geom_point()

# price by year
year_price <- ggplot(houses, aes(x = SALEYEAR, y = PRICE))
year_price_plot <- year_price + geom_point()


# price by month
month_price <- ggplot(houses, aes(x = SALEMONTH, y = PRICE))
month_price_plot <- month_price + geom_point()

# price by day of month
day_price <- ggplot(houses, aes(x = SALEDAY, y = PRICE))
day_price_plot <-  day_price + geom_point()

grid.arrange(room_price_plot, year_price_plot, month_price_plot, day_price_plot, nrow = 2,  ncol = 2)

```

###Plot Displaying Correlation Values Between Variables

```{r, echo = FALSE}

# Use corrplot to display a correlation matrix of that variables

corr_matrix <- cor(data.frame(houses$HF_BATHRM, houses$BATHRM, houses$ROOMS, houses$BEDRM,houses$AYB, houses$YR_RMDL, houses$PRICE, houses$SALEDAY, houses$SALEMONTH, houses$SALEYEAR, houses$STORIES, houses$LANDAREA, houses$GBA))
corrplot(corr_matrix, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

```



## Identification and Evaluation of Suitable Model

We first began multiple linear regression with all the predictor variables utilized (except for SALEDATE). This gave us a baseline R2 score to base feature transformation performance as well as any target variable transformations as well.

```{r 5.1, echo=FALSE}

# 5. Identification and evaluation of suitable model

fit <- lm(data = houses, PRICE ~ BATHRM + HF_BATHRM  + ROOMS + BEDRM + AYB + YR_RMDL + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)

# Review p-values, check sign of estimates

summary(fit)

```
Initially, we were surprised with an R<sup>2</sup> value of .6982 by using all variables with no transformations. We regarded this value as significant and established .6982 as our baseline for improvement.

Judging by the p-values, ROOMS, AYB, YR_RMDL, STORIES, and SALEMONTH appeared to be potentially insignificant. It is also visible, that the estmiated model coefficients had two negative values, BEDRM and YR_RMDL. Intuitively, the more bedrooms a house has and the more recent remodelling was conducted, the higher the price should be. This means these two varaibles would have positive correlation with the target variable price. BEDRM, however, did still have a significant p-value. 

To continue analysis of our base model, we also conducted an ANOVA test:
```{r 5.2, echo=FALSE}

# Review ANOVA and compare F statistic

anova(fit)

```


Next, we decidied to check the second assumption of ANOVA: that all errors must be normally distributed. We plotted the residuals and annotated their distribution:

```{r 5.3, echo=FALSE}

# Residual plot and look for non-constant variance

fit.df <- augment(fit)
ggplot(fit.df, aes(x = .fitted, y = .resid))+
  geom_point()+
  geom_hline(yintercept = 0, linetype = 2)+
  labs( x = "Fitted Values", y = "Residuals")

```

The plot above clearly shows that our model did not have normally distributed errors. To confirm this formally, we conducted a Shapiro-Wilk test:

```{r 5.4, echo=FALSE}
# Shapiro-Wilk test for normality

shapiro.test(fit$residuals)

```
Since the p-value for the Shapiro-Wilk test was essentially 0, this indicated our model did not have normal residuals, which confirms the information from the residual plot.

Before we began model improvement, we checked for the third assumption of ANOVA, that the variances of each group were equal:
```{r 5.5, echo=FALSE}
# ncvTest for constant variance

ncvTest(fit)

```
The practically 0 p-value indicated that we could not assume equal variances with our model.

These tests and exploratory analysis of our inital linear regression model revealed to us we could not validate ANOVA assumption number 2 or 3. This led us to the conclusion that we needed to conduct a Box-Cox test and appropriately transform our target variable to account for these issues.

The last model analysis we performed was reviewing the Variance Inflation Factors for evidence of multicollinearity.
```{r 5.6, echo=FALSE}

# Variance Inflation Factor (used to identify multicllinearity >= 10)

vif(fit)

```

A GVIF score of ten or more indicates multicollinearity. None of the variables were close to these thresholds, so multicollinearity was not present among our features.

#### Model Improvement

Now that we had analyzed our inital model and established areas of improvement, we then moved into refining our model. We first began with dropping variables that appeared to be insignificant according to high p-values. This included the variables: ROOMS, AYB, YR_RMDL, STORIES, and SALEMONTH. We began with the variable with the highest p-value and began dropping them from the model. If removing the variable decreased the R<sup>2</sup> value, we added the variable back and continued on to the next variable. The only positive result was dropping the variable AYB, which increased the R^2 score by .0002. Dropping ROOMS did not affect accuracy and removing the other variables lowered R<sup>2. We decided to keep the other variables and only drop AYB, which resulted in a new R^2 baseline at .6984.

We also considered the variables with negative coefficients that we outlined previously. YR_RMDL was already tested because of it's high p-value but we tested dropping BEDRM as well. This resulted in a lower R<sup>2</sup>, so we decided to keep the variable for the model. It could be the case, however, that in the region of this data set, having more bedrooms is undesirable past a certain point. This may be the case in a highly-populated with younger demographics.

Since multicollinearity was not present in the VIF test, we did not have any correlated variables to drop. For this data, we anticipated some correllation between variables. For example, as the number of rooms increases, it would be expected that the gross living square footage would also increase. We determined that these two are not necessarily collinear, as proved in the VIF test. A house may have several small rooms and little square footage while a large house may have few, but large rooms and still have a high level of square footage. This could also be said for rooms and bedrooms. Our concusion was that multicolliearity may be present in similar data sets, but was not found, or significant, in our data of 2000 houses.

We then progressed onto transforming the remaining variables. We conducted Box-Cox test on each predicitng variable to understand if there was a transformation that would somewhat normalize that variable. For some variables, we had to slightly manipulate them so they could processed (ex. added "1", Box-Cox cannot process variables with "0"). After analying the Box-Cox lambda values and applying the appropriate transformations, we added and removed those transformations until we recieved the highest R^2. Adding log(BEDRM + 1) and the log(GBA) brought our R^2 to .7269, which was an adequate improvement.

Next, we considered the target variable PRICE for transformation. According to our prelimminary tests, we could not conclude ANOVA assumptions two and three, that signaled to us that a target variable transformation may be necessary. We conducted a BOX-Cox test and received the following output:


```{r 5.7, echo=FALSE}
# Review R2 value
# From summary above: adjusted R^2 = .6984

# Drop non-significant predictor variables (Droped AYB: +.0002, Rooms: No change, other lower)
fit <- lm(data = houses, PRICE ~ BATHRM + HF_BATHRM  +  BEDRM + YR_RMDL + STORIES + SALEMONTH + SALEDAY + SALEYEAR + GBA + CNDTN + LANDAREA)
#summary(fit)

# If multicollinearity is present, drop one correlated variable (None present)

#Variable Transformations
#powerTransform(houses$HF_BATHRM+1) # .776
#powerTransform(houses$BEDRM+1) # -.130
#powerTransform(houses$STORIES+1) # -2.084
#powerTransform(houses$SALEMONTH) # .809
#powerTransform(houses$SALEYEAR-1990) # 1.48 - didn't help
#powerTransform(houses$GBA) # -.08 -> LOG
#powerTransform(houses$LANDAREA) # .35 -> SQRT

fit <- lm(data = houses, PRICE ~  BATHRM  + HF_BATHRM  + BEDRM + log(BEDRM+1) + STORIES  + SALEMONTH + SALEDAY + SALEYEAR  + GBA + log(GBA) + CNDTN + LANDAREA )
#summary(fit) # R^2 increased to .7269

# Transform the outcome variable if the residual plot looks suspicious
powerTransform(houses$PRICE) #.33 -> sqrt

# log lowers R2: .6589
fit1 <- lm(data = houses, log(PRICE) ~ BATHRM  + HF_BATHRM  + BEDRM + log(BEDRM+1) + STORIES  + SALEMONTH + SALEDAY + SALEYEAR  + GBA + log(GBA) + CNDTN + LANDAREA )
#summary(fit1)
# sqrt increase R2: .7481, drop YR_RMDL + .0001
fit2 <- lm(data = houses, sqrt(PRICE) ~ BATHRM  + HF_BATHRM  + BEDRM + log(BEDRM+1) + STORIES  + SALEMONTH + SALEDAY + SALEYEAR  + GBA + log(GBA) + CNDTN + LANDAREA )
#summary(fit2)
# inverse drastically decrease
fit3 <- lm(data = houses, I(1/PRICE) ~ BATHRM  + HF_BATHRM  + BEDRM + log(BEDRM+1) + STORIES  + SALEMONTH + SALEDAY + SALEYEAR  + GBA + log(GBA) + CNDTN + LANDAREA )
#summary(fit3)

```
A lambda value of 0.33 is roughly half way in between the log and sqrt transformation values. We tested both transformations and considered the resdiual plot for each transformation. Log actually lowered the R<sup>2</sup> to .6589 while sqrt increased the R<sup>2</sup> to .7481 Both residual plots greatly improved the residual distribution. We decided on the sqrt transformation because of it's increase in R<sup>2</sup> accuracy:
```{r 5.8, echo=FALSE}

fit_final <- lm(data = houses, sqrt(PRICE) ~  BATHRM  + HF_BATHRM  + BEDRM  + log(BEDRM+1) + STORIES  + SALEMONTH + SALEDAY + SALEYEAR  + GBA + log(GBA) + CNDTN + LANDAREA )
summary(fit_final) # R^2 increased to .7481

fit_final.df <- augment(fit_final)
ggplot(fit_final.df, aes(x = .fitted, y = .resid))+
  geom_point()+
  geom_hline(yintercept = 0, linetype = 2)+
  labs( x = "Fitted Values", y = "Residuals")

```

With an R<sup>2</sup> value of .7481, our model accounts for roughly 75% of variation in price from the predicting variables. This is the highest we were able to get the R^2 value following the process outlined above.

Also, as you can see, the plot of residuals looks much better and confirms the sqrt transformation aided our model.

To confirm our efforts of dropping variables and transforming them improved our accuracy, we implemented AIC and BIC for our original model and our final model:
```{r 5.9, echo=FALSE}

#using AIC & BIC for model comparison
"Initial Model AIC:"
AIC(fit) # AIC
"Initial Model BIC:"
BIC(fit) # BIC
"Final Model AIC:"
AIC(fit_final) # AIC
"Final Model BIC:"
BIC(fit_final) # BIC 

# The AIC and BIC for fit_final are both lower, so that is the better model

```
Since AIC and BIC are higher for our final model, our model adjustments increase in accuracy is confirmed.


#### Final Model

$Y = -49280 + 56.94X + 35.80X2 + -38.24X3 + 112.40X4 + 60.61X5 + 3.52X6 + 1.44X7 + 25.00X8 + 14.45X9 + -99.70X10 + 403.7X11 + 85.75X12 + 65.30X13 + 14.83X12 + .049X13$


## Application of the Model

At the beginning of our annalysis, we removed five records to test our final model, once we had it established. 

```{r 6.1, echo=FALSE}

# 6. Application of the model 

# Test on excluded rows
predict(fit, newdata = excl_rows, interval = "predict")

```

## Limitations and Assumptions

One limitation to the original iteration of our dataset was the SALEDATE. As an independent variable there were too many for them to be significant or to evaluate each individually. Also, the format of SALEDATE did not work well, especially due to the "0:00" after each date, presumably a timestamp. As mentioned in section 2, we split this variable to create new variables for each part of the date. Doing so resulted in new significant variables that improved our model.

In the future we would potentially include geographic data. In the original dataset there was longitude and latitude data, which was excluded from the dataset. Retrospectively, not being able to identify neighborhoods where homes are could be a limitation and including that data could make the model more accurate and useful.

One assumption that we make with this dataset, and thus our model, is the "Condition" variable. I would be interested in knowing who determined the condition of each home, when and by what means of evaluation. Is there a standard for such an assessment? This seems like something that could be subjective. Also we notice that there is no "poor" condition - the lowest level is "Fair", which could perpetuate subjectivity.

